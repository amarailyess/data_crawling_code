#!/usr/bin/env bash
#web scraping quotes website
 
if [ $# -ne 1 ]; then
	echo "usage $(basename $0) 'page number please'"
	exit -1

fi

curl=$(which curl)
outfile="output.txt"
#name=$(echo $1 | tr ' ' '+')
regex="--$1  "
url="https://quotes.toscrape.com/page/$1/"

function dump_webpage(){
	curl -o $outfile $url
	check_errors
}


#clean the webpage
function strip_html(){
	grep "<span>" $outfile |   's/<[<^>]*>//g' > temp.txt && cp temp.txt $outfile
	#grep "<small>" $outfile
	#grep -i "author" $outfile 
	#sed -n '/<span class="text" itemprop="text">/,/<\/span>/p' $outfile
	#sed -i "s/$regex/\n/g" $outfile
}

function print_quotes(){
	echo "All quotes!"
	while read quote; do
		echo "$(quote)"
	done < $outfile

}

 #checking for errors
function check_errors(){
  	[ $? -ne 0 ] && echo "Error downloading page ..." && exit -1
}

#######################
#      MAIN           #
#######################

dump_webpage
strip_html
#print_quotes
exit -1


